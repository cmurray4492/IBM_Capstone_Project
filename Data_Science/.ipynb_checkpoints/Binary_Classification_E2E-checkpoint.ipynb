{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries you need\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install shap\n",
    "# ! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries you'll be using\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from datetime import date\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import boto3\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset provided from Kaggle\n",
    "# We merge the the training and test dataset for now, as we'll run QA and transformations on all the data\n",
    "\n",
    "df_train = pd.read_csv('aug_train.csv')\n",
    "df_test = pd.read_csv('aug_test.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21287, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender  \\\n",
       "0         8949  city_103                   0.920   Male   \n",
       "1        29725   city_40                   0.776   Male   \n",
       "2        11561   city_21                   0.624    NaN   \n",
       "3        33241  city_115                   0.789    NaN   \n",
       "4          666  city_162                   0.767   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level  \\\n",
       "0  Has relevent experience       no_enrollment        Graduate   \n",
       "1   No relevent experience       no_enrollment        Graduate   \n",
       "2   No relevent experience    Full time course        Graduate   \n",
       "3   No relevent experience                 NaN        Graduate   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size    company_type last_new_job  \\\n",
       "0             STEM        >20          NaN             NaN            1   \n",
       "1             STEM         15        50-99         Pvt Ltd           >4   \n",
       "2             STEM          5          NaN             NaN        never   \n",
       "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4             STEM        >20        50-99  Funded Startup            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              36     1.0  \n",
       "1              47     0.0  \n",
       "2              83     0.0  \n",
       "3              52     1.0  \n",
       "4               8     0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkout the features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique on enrollee id\n",
    "\n",
    "df['enrollee_id'].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any person duplicates?\n",
    "\n",
    "df['duplicated'] = df.drop(columns = ['enrollee_id']).duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duplicated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['duplicated'] == True].index, inplace = True)\n",
    "df.head(2)\n",
    "print(f'New df size is {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive stats\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique and null counts, does everything look as expected?\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f' \\n {col.upper()} contains {df[col].nunique()} unique values and {df[col].isnull().sum()} nulls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unlabeled target rows\n",
    "\n",
    "df.dropna(subset=['target'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape[0])\n",
    "      \n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up 10/49 to 10-49\n",
    "\n",
    "df['company_size'] = df['company_size'].apply(lambda x: '10-49' if x == '10/49' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hours distribution\n",
    "\n",
    "df['training_hours'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn example\n",
    "\n",
    "sns.violinplot(data=df, x=\"education_level\", y=\"training_hours\", hue=\"target\", gridsize = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are classes balanced?\n",
    "\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of nulls in dataset\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't want to pass to model\n",
    "\n",
    "df_model = df.drop(['duplicated', 'enrollee_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any categorical columns require numeric indicator variables (i.e. pandas dummies)\n",
    "\n",
    "\n",
    "cat_cols = []\n",
    "\n",
    "for col in df_model.columns:\n",
    "    print('\\n')\n",
    "    print(f'Column {col} is of data type {df_model[col].dtype}')   \n",
    "    if df_model[col].dtype == 'object':\n",
    "        print('Creating dummies for it')\n",
    "        cat_cols.append(col)\n",
    "df_model = pd.get_dummies(df_model, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target col should be int 0 or 1\n",
    "\n",
    "df_model['target'] = pd.to_numeric(df_model['target'])\n",
    "df_model['target'] = df_model['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dummies look good\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what features are most correlated to the dependent variable\n",
    "# How should we interpret this?\n",
    "\n",
    "def gen_corr_grid(df, depvar):\n",
    "    corr_dict = {\n",
    "            'variable': [],\n",
    "            'corr': []\n",
    "        }\n",
    "    for col in list(df.columns):\n",
    "        if df[col].dtype not in ['object', '<M8[ns]'] and col != depvar :\n",
    "            r = df[depvar].corr(df[col])   \n",
    "            corr_dict['variable'].append(col)\n",
    "            corr_dict['corr'].append(r)\n",
    "    return pd.DataFrame(corr_dict).sort_values(by=['corr'], ascending=False)\n",
    "\n",
    "\n",
    "df_corrs = gen_corr_grid(df_model, 'target')\n",
    "df_corrs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test data to pass to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 split\n",
    "train, test = train_test_split(df_model, test_size=0.2)\n",
    "\n",
    "# Breakout identifies the feature cols so we break out our x (features) and y (target col) values in next cell\n",
    "breakout = list(set(train.columns) - set(['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y(test_in, train_in, breakout, depvar):\n",
    "     \n",
    "\n",
    "    train = train_in.copy()\n",
    "    test = test_in.copy()\n",
    "\n",
    "    X_train = train[breakout].copy()\n",
    "    X_test = test[breakout].copy()\n",
    "    \n",
    "    y_train = train[depvar]\n",
    "    y_test = test[depvar]\n",
    "        \n",
    "    X_columns = X_train.columns\n",
    "    \n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_columns = split_x_y(test, train, breakout, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm 80/20 split\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 splits\n",
    "\n",
    "cv_sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def fit_lgb(param_grid, X, y, cv):\n",
    "    \n",
    "    gbm = lgb.LGBMClassifier(objective='binary',\n",
    "                            feature_fraction= 0.9)\n",
    "    \n",
    "    grid_search = GridSearchCV(gbm, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv=cv,\n",
    "                               verbose=1,\n",
    "                              n_jobs=-1)   \n",
    "    \n",
    "    grid_search.fit(X=X, y=y.values.ravel())\n",
    "    \n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(grid_search.best_params_)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can test out other hyperparameter values to see if it improves performance\n",
    "\n",
    "param_grid = { 'learning_rate': [0.05],\n",
    "                'n_estimators': [400],\n",
    "                'max_depth': [5, 7],\n",
    "                'min_child_samples': [50, 200, 600],\n",
    "                'num_leaves': [31, 63] }\n",
    "\n",
    "grid_search = fit_lgb(param_grid, X_train, y_train, cv_sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass test data to our trained model. \n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "auc = metrics.roc_auc_score(y_true=y_test, y_score=y_pred)\n",
    "print(auc)\n",
    "\n",
    "fi = pd.Series(grid_search.best_estimator_.feature_importances_, index=X_columns).sort_values(ascending=False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SHAP values\n",
    "# Fit the explainer\n",
    "explainer = shap.Explainer(grid_search.best_estimator_.predict, X_test)\n",
    "# Calculates the SHAP values - this takes some time\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features ordered from highest to lowest impact on prediction\n",
    "\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do higher/lower values of each feature affect the prediction?\n",
    "\n",
    "shap.summary_plot(shap_values, plot_size = (12,12), max_display = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
